{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Step 1: Setup and Imports ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/25749\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import hopsworks\n",
    "import exclude.key\n",
    "\n",
    "# Hopsworks\n",
    "HOPSWORKS_API_KEY = exclude.key.HOPSWORKS_API_KEY\n",
    "FEATURE_GROUP_NAME = \"bars_near_london_bridge\"\n",
    "FEATURE_GROUP_VERSION = 1\n",
    "\n",
    "# Besttime API\n",
    "BESTTIME_API_KEY_PRIVATE = exclude.key.BESTTIME_API_KEY_PRIVATE\n",
    "BESTTIME_API_KEY_PUBLIC = exclude.key.BESTTIME_API_KEY_PUBLIC\n",
    "BAR_LOCATION = 'London Bridge, London'\n",
    "NUMBER_OF_BARS = 50\n",
    "\n",
    "# Connect to Hopsworks\n",
    "project = hopsworks.login(api_key_value=HOPSWORKS_API_KEY)\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Step 2: Create or Get Feature Group ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_feature_group():\n",
    "    try:\n",
    "        fg = fs.get_feature_group(name=FEATURE_GROUP_NAME, version=FEATURE_GROUP_VERSION)\n",
    "    except:\n",
    "        fg = fs.create_feature_group(\n",
    "            name=FEATURE_GROUP_NAME,\n",
    "            version=FEATURE_GROUP_VERSION,\n",
    "            description=\"Foot traffic data for bars near London Bridge\",\n",
    "            primary_key=['venue_name', 'day', 'hour'],\n",
    "            event_time='last_updated',\n",
    "            online_enabled=True\n",
    "        )\n",
    "    return fg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Step 3: Perform Venue Search ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_venue_search(api_key=BESTTIME_API_KEY_PRIVATE):\n",
    "    print(\"Performing venue search\")\n",
    "    endpoint = 'https://besttime.app/api/v1/venues/search'\n",
    "    params = {\n",
    "        'api_key_private': api_key,\n",
    "        'q': f'bars near {BAR_LOCATION}',\n",
    "        'num': NUMBER_OF_BARS,\n",
    "        'format': 'all'  # Retrieve full forecast data\n",
    "    }\n",
    "    response = requests.post(endpoint, params=params)\n",
    "    search_data = response.json()\n",
    "    \n",
    "    job_progress_url = search_data['_links']['venue_search_progress']\n",
    "    print(f\"Venue search initiated. Progress URL: {job_progress_url}\")\n",
    "    return job_progress_url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Step 4: Retrieve Venue Search Results ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_venue_search_results(job_progress_url):\n",
    "    print(\"Retrieving venue search results...\")\n",
    "    while True:\n",
    "        response = requests.get(job_progress_url)\n",
    "        progress_data = response.json()\n",
    "        if progress_data['job_finished']:\n",
    "            break\n",
    "        time.sleep(5)\n",
    "    venues = progress_data['venues']\n",
    "    print(f\"Found {len(venues)} venues.\")\n",
    "    return venues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Step 5: Extract Historical Data ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_historical_data(venues):\n",
    "    print(\"Extracting historical data...\")\n",
    "    historical_data = []\n",
    "    for venue in venues:\n",
    "        if venue['forecast']:  # Check if venue has forecast data\n",
    "            forecast_data = venue['venue_foot_traffic_forecast']\n",
    "            for day_data in forecast_data['analysis']:\n",
    "                for hour_data in day_data['hour_analysis']:\n",
    "                    historical_data.append([\n",
    "                        venue['venue_name'],\n",
    "                        venue['venue_address'],\n",
    "                        day_data['day_info']['day_text'],\n",
    "                        hour_data['hour'],\n",
    "                        hour_data['intensity_txt']\n",
    "                    ])\n",
    "    return historical_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Step 6: Backfill Historical Data ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backfill_historical_data(api_key=BESTTIME_API_KEY_PRIVATE):\n",
    "    print(\"Starting backfill\"\n",
    "    # Perform venue search and retrieve results\n",
    "    job_progress_url = perform_venue_search(api_key)\n",
    "    venues = retrieve_venue_search_results(job_progress_url)\n",
    "\n",
    "    # Extract historical data from the venue search results\n",
    "    historical_data = extract_historical_data(venues)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_historical = pd.DataFrame(historical_data, columns=['Venue Name', 'Venue Address', 'Day', 'Hour', 'Busyness'])\n",
    "\n",
    "    # Rename columns to match feature store requirements\n",
    "    df_historical.columns = ['venue_name', 'venue_address', 'day', 'hour', 'busyness']\n",
    "    \n",
    "    # Add last_updated column\n",
    "    df_historical['last_updated'] = datetime.datetime.now()\n",
    "\n",
    "    # Get or create the feature group\n",
    "    fg = get_or_create_feature_group()\n",
    "\n",
    "    # Insert historical data into the feature group\n",
    "    fg.insert(df_historical, write_options={\"wait\": True})\n",
    "    print(\"Historical data backfilled successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Step 7: Query Real-Time Data ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_realtime_data(venue_id, api_key=BESTTIME_API_KEY_PRIVATE):\n",
    "    endpoint = 'https://besttime.app/api/v1/venues/analysis'\n",
    "    params = {\n",
    "        'api_key_private': api_key,\n",
    "        'venue_id': venue_id,\n",
    "        'format': 'all'\n",
    "    }\n",
    "    response = requests.post(endpoint, params=params)\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Step 8: Update Real-Time Data ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_realtime_data(api_key=BESTTIME_API_KEY_PRIVATE):\n",
    "    # Perform venue search and retrieve results\n",
    "    job_progress_url = perform_venue_search(api_key)\n",
    "    venues = retrieve_venue_search_results(job_progress_url)\n",
    "\n",
    "    # Extract real-time data from the venue search results\n",
    "    historical_data = extract_historical_data(venues)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_historical = pd.DataFrame(historical_data, columns=['Venue Name', 'Venue Address', 'Day', 'Hour', 'Busyness'])\n",
    "\n",
    "    # Rename columns to match feature store requirements\n",
    "    df_historical.columns = ['venue_name', 'venue_address', 'day', 'hour', 'busyness']\n",
    "    \n",
    "    # Add last_updated column\n",
    "    df_historical['last_updated'] = datetime.datetime.now()\n",
    "\n",
    "    # Insert real-time data into the feature group\n",
    "    fg = get_or_create_feature_group()\n",
    "    fg.insert(df_historical, write_options={\"wait\": True})\n",
    "    print(\"Real-time data updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Step 9: Main Function ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Call backfill_historical_data() once to backfill\n",
    "    # Uncomment the next line to perform backfill\n",
    "    # backfill_historical_data()\n",
    "\n",
    "    # Call update_realtime_data() periodically to update with real-time data\n",
    "    update_realtime_data()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python31012",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
